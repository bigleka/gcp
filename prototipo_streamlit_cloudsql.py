"""
Prot√≥tipo completo: Streamlit app para listar inst√¢ncias Cloud SQL (Postgres) e executar SQL em m√∫ltiplas inst√¢ncias.

Funcionalidades inclu√≠das:
- Suporta upload de JSON (Service Account ou ADC gerado por `gcloud auth application-default login`).
- Suporta usar ADC local sem upload (checkbox).
- Lista inst√¢ncias Cloud SQL (sqladmin API) e tenta listar AlloyDB (discovery).
- Filtra por label (ex: `environment`) e permite sele√ß√£o por checkboxes.
- Informa usu√°rio/senha do banco e executa SQL em paralelo nas inst√¢ncias selecionadas.
- Exibe resultados por inst√¢ncia (dataframe ou erro).

Observa√ß√µes importantes (seguran√ßa e produ√ß√£o):
- Este prot√≥tipo usa conex√µes diretas por IP p√∫blico quando dispon√≠vel.
- N√£o armazene senhas em texto claro em produ√ß√£o; use Secret Manager.

Como rodar:
1. Crie um virtualenv e ative.
2. pip install streamlit google-api-python-client google-auth google-auth-httplib2 psycopg2-binary
3. streamlit run prototipo_streamlit_cloudsql.py

"""

"""
Cloud SQL / AlloyDB Multi-Project ‚Äî Projetos + Hist√≥rico + Status
-----------------------------------------------------------------
Melhorias:
1Ô∏è‚É£ √çcones de status (üü¢ online / üî¥ offline)
2Ô∏è‚É£ Agrupamento por projeto (colaps√°veis)
4Ô∏è‚É£ Hist√≥rico local de queries executadas (sidebar)
"""

import streamlit as st
import requests
import time
import traceback
import psycopg2
import psycopg2.extras
from datetime import datetime
from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials
from google.auth import default as google_default
from concurrent.futures import ThreadPoolExecutor, as_completed

st.set_page_config(page_title="Cloud SQL Multi-Project Enhanced", layout="wide")
st.title("üß≠ Cloud SQL / AlloyDB Multi-Project ‚Äî Projetos + Hist√≥rico + Status")

SCOPES = ["https://www.googleapis.com/auth/cloud-platform"]

# -----------------------------
# Helpers
# -----------------------------
def load_creds_from_file(path):
    creds = Credentials.from_authorized_user_file(path, scopes=SCOPES)
    if not creds.valid and creds.refresh_token:
        creds.refresh(Request())
    return creds

def try_adc_local():
    creds, project = google_default(scopes=SCOPES)
    if not creds.valid and creds.refresh_token:
        creds.refresh(Request())
    return creds, project

# -----------------------------
# API: CloudSQL / AlloyDB listing
# -----------------------------
@st.cache_data(show_spinner=False)
def list_all_projects(_creds):
    headers = {"Authorization": f"Bearer {_creds.token}"}
    url = "https://cloudresourcemanager.googleapis.com/v1/projects"
    projects = []
    while url:
        r = requests.get(url, headers=headers)
        if r.status_code != 200:
            break
        data = r.json()
        for p in data.get("projects", []):
            if p.get("lifecycleState") == "ACTIVE":
                projects.append(p["projectId"])
        url = f"https://cloudresourcemanager.googleapis.com/v1/projects?pageToken={data.get('nextPageToken')}" if data.get("nextPageToken") else None
    return sorted(projects)

@st.cache_data(show_spinner=False)
def list_cloudsql_instances_for_project(_creds, project_id):
    headers = {"Authorization": f"Bearer {_creds.token}"}
    url = f"https://sqladmin.googleapis.com/v1/projects/{project_id}/instances"
    r = requests.get(url, headers=headers)
    if r.status_code != 200:
        return []
    items = r.json().get("items", [])
    return [
        {
            "project": project_id,
            "name": it.get("name"),
            "type": "cloudsql",
            "state": it.get("state"),
            "ipAddresses": it.get("ipAddresses", []),
            "labels": it.get("settings", {}).get("userLabels", {}),
            "databaseVersion": it.get("databaseVersion"),
        }
        for it in items
    ]

@st.cache_data(show_spinner=False)
def list_alloydb_clusters_for_project(_creds, project_id):
    headers = {"Authorization": f"Bearer {_creds.token}"}
    url = f"https://alloydb.googleapis.com/v1/projects/{project_id}/locations/-/clusters"
    r = requests.get(url, headers=headers)
    if r.status_code != 200:
        return []
    clusters = r.json().get("clusters", [])
    return [
        {
            "project": project_id,
            "name": c.get("name"),
            "type": "alloydb",
            "state": c.get("state"),
            "ipAddresses": [],
            "labels": c.get("labels", {}),
            "databaseVersion": c.get("databaseVersion"),
        }
        for c in clusters
    ]

@st.cache_data(show_spinner=False)
def list_all_instances_for_all_projects(_creds):
    all_instances = []
    for p in list_all_projects(_creds):
        try:
            all_instances += list_cloudsql_instances_for_project(_creds, p)
        except Exception as e:
            st.warning(f"Erro Cloud SQL em {p}: {e}")
        try:
            all_instances += list_alloydb_clusters_for_project(_creds, p)
        except Exception as e:
            st.warning(f"Erro AlloyDB em {p}: {e}")
    return all_instances

# -----------------------------
# Databases via Cloud SQL Admin API
# -----------------------------
def list_databases_via_api(inst, creds):
    if inst["type"] != "cloudsql":
        return []
    headers = {"Authorization": f"Bearer {creds.token}"}
    url = f"https://sqladmin.googleapis.com/v1/projects/{inst['project']}/instances/{inst['name']}/databases"
    r = requests.get(url, headers=headers)
    if r.status_code != 200:
        return []
    data = r.json().get("items", [])
    ignore = {"template0", "template1", "cloudsqladmin"}
    return sorted([d["name"] for d in data if d["name"] not in ignore])

def list_databases_parallel(insts, creds, max_workers=10):
    results = {}
    with ThreadPoolExecutor(max_workers=max_workers) as ex:
        futs = {ex.submit(list_databases_via_api, i, creds): i for i in insts}
        for fut in as_completed(futs):
            inst = futs[fut]
            key = f"{inst['project']}|{inst['name']}"
            try:
                results[key] = fut.result()
            except Exception:
                results[key] = []
    return results

# -----------------------------
# SQL execution helpers
# -----------------------------
def choose_ip_for_instance(inst):
    ips = inst.get("ipAddresses", [])
    if not ips:
        return None
    first = ips[0]
    if isinstance(first, dict):
        return first.get("ipAddress")
    return first

def run_sql_on_instance(inst, user, password, db, sql, timeout=10):
    host = choose_ip_for_instance(inst)
    out = {"instance": inst["name"], "project": inst["project"], "host": host, "success": False}
    if not host:
        out["error"] = "Sem IP p√∫blico."
        return out
    try:
        conn = psycopg2.connect(host=host, user=user, password=password, dbname=db, connect_timeout=timeout)
        cur = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)
        cur.execute(sql)
        try:
            out["rows"] = cur.fetchall()
        except psycopg2.ProgrammingError:
            out["rows"] = None
            out["rows_affected"] = cur.rowcount
        conn.commit()
        conn.close()
        out["success"] = True
    except Exception as e:
        out["error"] = str(e)
    return out

# -----------------------------
# Session state init
# -----------------------------
if "instances_cache" not in st.session_state:
    st.session_state.instances_cache = None
if "creds_cache" not in st.session_state:
    st.session_state.creds_cache = None
if "databases_cache" not in st.session_state:
    st.session_state.databases_cache = {}
if "query_history" not in st.session_state:
    st.session_state.query_history = []

# -----------------------------
# Sidebar - Hist√≥rico de queries
# -----------------------------
with st.sidebar.expander("üìú Hist√≥rico de queries", expanded=False):
    if st.session_state.query_history:
        for q in reversed(st.session_state.query_history[-15:]):
            st.markdown(
                f"üïí `{q['time']}` ‚Äî **{q['successes']}/{q['instances']} ok**\n\n```sql\n{q['sql'][:200]}\n```"
            )
    else:
        st.caption("Nenhuma query executada ainda.")

# -----------------------------
# UI principal
# -----------------------------
st.markdown("### üîê Autentica√ß√£o e carregamento de inst√¢ncias")
col_a, col_b, col_c = st.columns([2, 2, 3])
with col_a:
    cred_file = st.file_uploader("JSON de credenciais", type=["json"])
with col_b:
    use_adc = st.checkbox("Usar ADC local se nenhum arquivo enviado", True)

cols_btn = st.columns([2, 2, 6])
with cols_btn[0]:
    list_btn = st.button("üîÑ Listar todas inst√¢ncias")
with cols_btn[1]:
    list_db_btn = st.button("üìö Listar databases via API")

# -----------------------------
# Carregar inst√¢ncias
# -----------------------------
if list_btn:
    try:
        if cred_file:
            with open("._temp_cred.json", "wb") as f:
                f.write(cred_file.getvalue())
            creds = load_creds_from_file("._temp_cred.json")
        elif use_adc:
            creds, _ = try_adc_local()
        else:
            creds = None
        if creds:
            with st.spinner("Carregando inst√¢ncias via API..."):
                all_instances = list_all_instances_for_all_projects(creds)
            st.session_state.instances_cache = all_instances
            st.session_state.creds_cache = creds
            st.success(f"{len(all_instances)} inst√¢ncias carregadas.")
    except Exception as e:
        st.error(f"Erro: {e}")

# -----------------------------
# Exibi√ß√£o das inst√¢ncias agrupadas
# -----------------------------
if st.session_state.instances_cache:
    creds = st.session_state.creds_cache
    insts = st.session_state.instances_cache

    def is_online(i):
        return (i["state"] or "").upper() in ("RUNNABLE", "READY", "RUNNING")

    grouped = {}
    for inst in insts:
        grouped.setdefault(inst["project"], []).append(inst)

    if list_db_btn and creds:
        with st.spinner("Listando bases via Cloud SQL Admin API..."):
            all_flat = [i for plist in grouped.values() for i in plist]
            dbmap = list_databases_parallel(all_flat, creds)
        for k, v in dbmap.items():
            st.session_state.databases_cache[k] = v
        st.success("Bases listadas com sucesso.")

    selected = []
    st.markdown("### ‚òÅÔ∏è Inst√¢ncias por projeto")

    for proj, inst_list in grouped.items():
        with st.expander(f"üì¶ Projeto `{proj}` ({len(inst_list)} inst√¢ncias)", expanded=False):
            for inst in inst_list:
                cols = st.columns([4, 1, 3, 3, 3])
                online_flag = is_online(inst)
                status_icon = "üü¢" if online_flag else "üî¥"
                with cols[0]:
                    st.write(f"{status_icon} **{inst['name']}**")
                    st.caption(f"{inst['type']} ‚Ä¢ {inst.get('databaseVersion','')}")
                with cols[1]:
                    chk = st.checkbox("", key=f"{inst['project']}|{inst['name']}")
                with cols[2]:
                    st.write(choose_ip_for_instance(inst) or "---")
                key = f"{inst['project']}|{inst['name']}"
                dbs = st.session_state.databases_cache.get(key, [])
                with cols[3]:
                    if dbs:
                        st.selectbox("DB", dbs, key=f"dbsel|{key}", label_visibility="collapsed")
                    else:
                        st.selectbox("DB", ["(nenhuma)"], key=f"dbsel|{key}", disabled=True, label_visibility="collapsed")
                with cols[4]:
                    st.write(f"{inst['state']}")
                if chk:
                    selected.append(inst)

    st.divider()
    st.write(f"Inst√¢ncias selecionadas: **{len(selected)}**")

    db_user = st.text_input("DB user", "postgres")
    db_pass = st.text_input("DB password", type="password")
    sql = st.text_area("SQL a executar", "SELECT version();")
    max_workers = st.slider("Paralelismo", 1, 20, 8)

    if st.button("‚ñ∂Ô∏è Executar SQL"):
        if not selected:
            st.warning("Nenhuma inst√¢ncia selecionada.")
        elif not db_pass:
            st.warning("Informe a senha.")
        else:
            with st.spinner("Executando SQL..."):
                results = []
                with ThreadPoolExecutor(max_workers=max_workers) as ex:
                    futmap = {
                        ex.submit(
                            run_sql_on_instance,
                            inst,
                            db_user,
                            db_pass,
                            st.session_state.get(f"dbsel|{inst['project']}|{inst['name']}", "postgres"),
                            sql,
                        ): inst for inst in selected
                    }
                    for fut in as_completed(futmap):
                        inst = futmap[fut]
                        try:
                            res = fut.result()
                        except Exception as e:
                            res = {"instance": inst["name"], "project": inst["project"], "success": False, "error": str(e)}
                        results.append((inst, res))

            # Exibir resultados
            success_count = 0
            for inst, r in results:
                st.subheader(f"{inst['project']} / {inst['name']}")
                if r["success"]:
                    success_count += 1
                    st.success("OK")
                    if r.get("rows"):
                        st.dataframe(r["rows"])
                    else:
                        st.caption("Query executada com sucesso.")
                else:
                    st.error(r.get("error"))

            # Adicionar ao hist√≥rico
            st.session_state.query_history.append({
                "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "sql": sql.strip(),
                "instances": len(selected),
                "successes": success_count,
            })
else:
    st.info("Envie credenciais e clique em 'Listar todas inst√¢ncias'.")
